<!DOCTYPE html>
<html lang="en-us">
  
  <head>
    <meta http-equiv="Content-Security-Policy" content="script-src 'self' 'unsafe-eval' 'unsafe-inline'; object-src 'self'">
    <title>Real-time Local Speech To Text</title>

    <style>
      :root {
        --primary-color: #0078D4;
        --background-color: #f9f9f9;
        --card-background: #ffffff;
        --text-color: #323130;
        --border-radius: 4px;
        --spacing: 20px;
      }

      body {
        font-family: 'Segoe UI', -apple-system, BlinkMacSystemFont, sans-serif;
        font-size: 14px;
        margin: 0;
        padding: var(--spacing);
        background-color: var(--background-color);
        color: var(--text-color);
        line-height: 1.5;
      }

      #main-container {
        max-width: 1200px;
        margin: 0 auto;
        padding: var(--spacing);
      }

      .card {
        background: var(--card-background);
        border-radius: var(--border-radius);
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        padding: var(--spacing);
        margin-bottom: var(--spacing);
      }

      button {
        background-color: var(--primary-color);
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: var(--border-radius);
        cursor: pointer;
        font-size: 14px;
        font-weight: 500;
        transition: background-color 0.2s ease;
      }

      button:hover {
        background-color: #106EBE;
      }

      button:disabled {
        background-color: #C8C8C8;
        cursor: not-allowed;
      }

      button:not(:last-child) {
        margin-right: 10px;
      }

      .response-container {
        font-family: 'Consolas', 'Monaco', monospace;
        font-size: 14px;
        line-height: 1.6;
        white-space: pre-wrap;
        word-wrap: break-word;
        background: #f5f5f5;
        border: 1px solid #E1E1E1;
        border-radius: var(--border-radius);
        padding: 15px;
        margin-top: 10px;
        min-height: 100px;
        max-height: 400px;
        overflow-y: auto;
        width: 100%;
        box-sizing: border-box;
      }

      .transcription-container, .llm-response-container {
        margin-top: var(--spacing);
      }

      #state-transcribed {
        background-color: var(--card-background);
        border: 1px solid #E1E1E1;
      }

      h3 {
        margin-bottom: 10px;
      }

      .input-group {
        margin-bottom: var(--spacing);
      }

      #llm-query-input {
        width: 100%;
        min-height: 80px;
        padding: 10px;
        border: 1px solid #E1E1E1;
        border-radius: var(--border-radius);
        font-family: inherit;
        font-size: 14px;
        resize: vertical;
        margin-bottom: 10px;
      }

      #output {
        width: 100%;
        margin: var(--spacing) 0;
        padding: 15px;
        background-color: #2D2D2D;
        color: #E8E8E8;
        font-family: 'Cascadia Code', 'Consolas', monospace;
        font-size: 13px;
        border-radius: var(--border-radius);
        white-space: pre-wrap;
        overflow-x: auto;
      }

      #state {
        margin-top: var(--spacing);
      }

      .response-container {
        background: #f5f5f5;
        border-radius: var(--border-radius);
        padding: 15px;
        margin-top: 10px;
        max-height: 400px;
        overflow-y: auto;
      }

      #llm-output, #direct-query-response {
        font-family: 'Consolas', 'Monaco', monospace;
        font-size: 14px;
        line-height: 1.6;
        margin: 0;
        white-space: pre-wrap;
        word-wrap: break-word;
      }

      .model-info {
        display: flex;
        flex-direction: column;
        gap: 10px;
      }

      .model-info div {
        display: flex;
        align-items: center;
        gap: 8px;
      }

      .model-info strong {
        color: var(--text-color);
        min-width: 120px;
      }

      #ollama-model-status, #model-whisper-status {
        color: var(--primary-color);
        font-weight: 500;
      }

      #fetch-whisper-progress {
        color: #666;
        font-size: 0.9em;
        margin-left: 8px;
      }

      .status-container {
        margin-bottom: var(--spacing);
      }

      hr {
        border: none;
        border-top: 1px solid #E1E1E1;
        margin: var(--spacing) 0;
      }

      .response-item {
        margin-bottom: 15px;
        padding: 15px;
        border-bottom: 1px solid #E1E1E1;
        animation: fadeIn 0.3s ease-in;
      }

      .streaming-response {
        display: inline-block;
        min-height: 1em;
      }

      @keyframes fadeIn {
        from { opacity: 0; transform: translateY(5px); }
        to { opacity: 1; transform: translateY(0); }
      }

      .response-item:last-child {
        border-bottom: none;
      }

      #model-whisper {
        margin-bottom: var(--spacing);
      }

      #state-status {
        color: var(--primary-color);
        font-weight: 500;
      }

      #system-prompt-container {
        margin: var(--spacing) 0;
      }

      #system-prompt {
        width: 100%;
        padding: 10px;
        border: 1px solid #E1E1E1;
        border-radius: var(--border-radius);
        font-family: inherit;
        font-size: 14px;
        resize: vertical;
        margin-bottom: 10px;
      }

      #llm-response {
        margin-top: var(--spacing);
      }

      #llm-output {
        max-height: 400px;
        overflow-y: auto;
        padding: 15px;
        background-color: var(--card-background);
        border: 1px solid #E1E1E1;
        border-radius: var(--border-radius);
        font-family: inherit;
        line-height: 1.6;
      }

      .response-wrapper {
        overflow-y: auto;
        max-height: 400px;
      }
    </style>

  </head>
  <body>
    <div id="main-container">
      <h1>Real-time Local STT / LLM Tester</h1>

      <div id="system-prompt-container" class="card">
        <h3>LLM Settings</h3>
        <div class="input-group">
          <label for="ollama-model">Ollama Model:</label>
          <input type="text" id="ollama-model" placeholder="Enter model name (e.g., deepseek-r1:7b)" style="width: 100%; margin-bottom: 10px; padding: 8px; border-radius: var(--border-radius); border: 1px solid #ccc;">
          <button id="update-model" onclick="updateModel()">Update Model</button>
        </div>
        <div class="input-group">
          <label for="system-prompt">System Prompt:</label>
          <textarea id="system-prompt" placeholder="Enter your system prompt here..." rows="3" style="width: 100%; margin-bottom: 10px; padding: 8px; border-radius: var(--border-radius); border: 1px solid #ccc;"></textarea>
          <button id="update-system-prompt" onclick="updateSystemPrompt()">Update System Prompt</button>
        </div>
      </div>

      <div id="input" class="card">
        <h3>STT Controls</h3>
        <button id="start" onclick="onStart()" disabled>Start Listening</button>
        <button id="stop" onclick="onStop()" disabled>Stop Listening</button>
      </div>

      <div id="state" class="card">
        <div class="status-container">
          <h3>STT Status</h3>
          <span id="state-status">not started</span>
        </div>

        <div class="transcription-container">
          <h3>Transcription</h3>
          <div id="state-transcribed" class="response-container">[The transcribed text will be displayed here]</div>
        </div>

        <div class="llm-response-container">
          <h3>LLM Response</h3>
          <div class="response-wrapper">
            <div id="llm-output" class="response-container">[LLM responses will appear here]</div>
          </div>
        </div>
      </div>

      <div id="model-ollama" class="card">
        <h2>Direct LLM Query</h2>
        <div class="input-group">
          <textarea id="llm-query-input" placeholder="Enter your query here..." rows="3" style="width: 100%; margin-bottom: 10px; padding: 8px; border-radius: var(--border-radius); border: 1px solid #ccc;"></textarea>
          <button id="llm-query-button" onclick="executeQuery()" style="margin-bottom: 10px;">Execute Query</button>
        </div>
        <div class="response-wrapper">
          <div id="direct-query-response" class="response-container"></div>
        </div>
      </div>

    </div>

    <script type="text/javascript" src="./src/helpers.js"></script>
    <script type="text/javascript" src="./src/ollama.js"></script>
    <script>
      let globalApi = null;
      let ollamaService = null;

      // Initialize OllamaService when the page loads
      document.addEventListener('DOMContentLoaded', () => {
        ollamaService = new OllamaService();
        // Set initial values in UI
        document.getElementById('system-prompt').value = ollamaService.systemPrompt;
        document.getElementById('ollama-model').value = ollamaService.model;
        console.log('OllamaService initialized with system prompt:', ollamaService.systemPrompt);
      });

      function updateModel() {
        const modelInput = document.getElementById('ollama-model');
        const newModel = modelInput.value.trim();
        
        if (newModel) {
          ollamaService.model = newModel;
          console.log('Model updated to:', newModel);
        } else {
          alert('Please enter a model name');
        }
      }

      function updateSystemPrompt() {
        const promptInput = document.getElementById('system-prompt');
        const newPrompt = promptInput.value.trim();
        
        if (newPrompt) {
          ollamaService.systemPrompt = newPrompt;
          console.log('System prompt updated to:', newPrompt);
        } else {
          alert('Please enter a system prompt');
        }
      }

      // Wait for the window.api to be available
      function waitForApi() {
        return new Promise((resolve, reject) => {
          console.log('Waiting for API...');
          console.log('Current window.api:', window.api);
          
          if (globalApi) {
            console.log('Using cached API');
            resolve(globalApi);
            return;
          }

          if (window.api) {
            console.log('API found immediately');
            console.log('API methods:', Object.keys(window.api));
            globalApi = window.api;
            resolve(globalApi);
            return;
          }
          
          let attempts = 0;
          const maxAttempts = 50; // 5 seconds maximum wait
          
          const checkInterval = setInterval(() => {
            attempts++;
            console.log(`Checking for API (attempt ${attempts})...`);
            
            if (window.api) {
              clearInterval(checkInterval);
              console.log('API found after waiting');
              console.log('API methods:', Object.keys(window.api));
              globalApi = window.api;
              resolve(globalApi);
            } else if (attempts >= maxAttempts) {
              clearInterval(checkInterval);
              const error = new Error('API not available after 5 seconds');
              console.error(error);
              reject(error);
            }
          }, 100);
        });
      }

      // Initialize API on page load
      document.addEventListener('DOMContentLoaded', async () => {
        console.log('DOM Content Loaded');
        try {
          const api = await waitForApi();
          console.log('API initialized successfully');
          console.log('Available API methods:', Object.keys(api));
          
          // Test the API
          if (typeof api.directOllamaQuery !== 'function') {
            console.error('directOllamaQuery is not available');
            console.log('API object:', api);
          } else {
            console.log('directOllamaQuery is available');
          }
        } catch (error) {
          console.error('Failed to initialize API:', error);
        }
      });

      async function executeQuery() {
        const queryInput = document.getElementById('llm-query-input');
        const responseDiv = document.getElementById('direct-query-response');
        const queryButton = document.getElementById('llm-query-button');
        
        if (!queryInput.value.trim()) {
          alert('Please enter a query');
          return;
        }

        try {
          // Clear and disable input
          queryButton.disabled = true;
          responseDiv.innerText = '';
          
          // Get API and make query
          const api = await waitForApi();
          if (!api || typeof api.directOllamaQuery !== 'function') {
            throw new Error('API not available');
          }

          console.log('Current system prompt:', ollamaService.systemPrompt);
          console.log('Current model:', ollamaService.model);

          // Create a text node for updates
          const textNode = document.createTextNode('');
          responseDiv.appendChild(textNode);
          
          await api.directOllamaQuery(
            queryInput.value,
            (chunk) => {
              if (chunk && chunk.length > 0) {
                // Update text node content
                textNode.textContent += chunk;
                responseDiv.scrollTop = responseDiv.scrollHeight;
              }
            },
            ollamaService.systemPrompt,
            ollamaService.model
          );
        } catch (error) {
          responseDiv.innerText = 'Error: ' + (error.message || 'Unknown error occurred');
        } finally {
          queryButton.disabled = false;
        }
      }

      async function onStop() {
        if (!instance) {
          return;
        }

        document.getElementById('start').disabled = false;
        document.getElementById('stop').disabled = true;

        stopRecording();
        clearInterval(intervalUpdate);

        // Reset status text
        document.getElementById('state-status').innerHTML = 'not started';

        // Only send the accumulated text to the LLM when stopping
        if (accumulatedTranscription && accumulatedTranscription.trim().length > 0) {
          try {
            console.log('Processing transcription:', accumulatedTranscription.trim());
            const llmOutput = document.getElementById('llm-output');
            llmOutput.textContent = '';
            
            const api = await waitForApi();
            console.log('Got API instance for transcription processing');
            
            await api.directOllamaQuery(
              accumulatedTranscription.trim(),
              (chunk) => {
                console.log('Renderer received transcription response chunk:', chunk);
                if (chunk && chunk.length > 0) {
                  // Append each chunk to the response div
                  llmOutput.textContent += chunk;
                  // Force scroll to bottom to show new content
                  llmOutput.scrollTop = llmOutput.scrollHeight;
                }
              },
              ollamaService.systemPrompt,
              ollamaService.model
            );
            console.log('Transcription processing complete');
          } catch (error) {
            console.error('Error getting LLM response:', error);
            const llmOutput = document.getElementById('llm-output');
            llmOutput.textContent = 'Error: ' + error.message;
          }
        }
      }
    </script>
    <script>
       // web audio context
       var context = null;

      // audio data
      var audio = null;
      var audio0 = null;

      // the stream instance
      var instance = null;

      // model names
      var model_whisper = 'base-en-q5_1';
      var model_llm = 'deepseek-r1:7b';

      function updateModelStatus() {
        if (ollamaService) {
          const modelStatus = document.getElementById('ollama-model-status');
          modelStatus.textContent = ollamaService.model;
        }
      }

      // Initialize the model display
      document.addEventListener('DOMContentLoaded', function() {
        document.getElementById('model-whisper-status').textContent = model_whisper;
        document.getElementById('ollama-model-status').textContent = model_llm;
      });

      //
      // fetch models
      //

      let dbVersion = 1;
      let dbName = 'whisper-voice';
      let indexedDB =
        window.indexedDB ||
        window.mozIndexedDB ||
        window.webkitIndexedDB ||
        window.msIndexedDB;

      function storeFS(fname, buf) {
        // write to WASM file using FS_createDataFile
        // if the file exists, delete it
        try {
          if (window.Module && window.Module.FS_unlink) {
            window.Module.FS_unlink(fname);
          }
        } catch (e) {
          // ignore
        }

        if (!window.Module || !window.Module.FS_createDataFile) {
          console.error('Module or FS_createDataFile not available');
          return;
        }

        window.Module.FS_createDataFile('/', fname, buf, true, true);

        printTextarea(
          'storeFS: stored model: ' + fname + ' size: ' + buf.length
        );

        // Enable start button and disable stop button only if Module is ready
        if (window.Module && window.Module.ready) {
          document.getElementById('start').disabled = false;
          document.getElementById('stop').disabled = true;
        } else {
          console.log('Waiting for Module to be ready...');
        }
      }

      // Initialize Module configuration
      window.Module = {
        ready: false,
        print: function(text) {
          if (typeof printTextarea === 'function') {
            printTextarea(text);
          } else {
            console.log(text);
          }
        },
        printErr: function(text) {
          if (typeof printTextarea === 'function') {
            printTextarea(text);
          } else {
            console.error(text);
          }
        },
        onRuntimeInitialized: function() {
          console.log('Module runtime initialized');
          window.Module.ready = true;
          
          // Enable start button if model is already loaded
          if (document.getElementById('start').disabled) {
            document.getElementById('start').disabled = false;
            document.getElementById('stop').disabled = true;
          }
        }
      };

      function loadWhisper(model) {
        let urls = {
          'tiny.en': './src/ggml-model-whisper-tiny.en.bin',
          'tiny-en-q5_1': './src/ggml-model-whisper-tiny.en-q5_1.bin',
          'base-en-q5_1': './src/ggml-model-whisper-base.en-q5_1.bin',
        };

        let sizes = {
          'tiny.en': 59,
          'tiny-en-q5_1': 32,
          'base-en-q5_1': 77,
        };

        let url = urls[model];
        let dst = 'whisper.bin';
        let size_mb = sizes[model];

        model_whisper = model;

        cbProgress = function (p) {
          let el = document.getElementById('fetch-whisper-progress');
          el.innerHTML = Math.round(100 * p) + '%';
        };

        cbCancel = function () {
          var el;
          el = document.getElementById('fetch-whisper-tiny-en');
          if (el) el.style.display = 'inline-block';

          el = document.getElementById('fetch-whisper-tiny-en-q5_1');
          if (el) el.style.display = 'inline-block';
          el = document.getElementById('fetch-whisper-base-en-q5_1');
          if (el) el.style.display = 'inline-block';

          el = document.getElementById('model-whisper-status');
          if (el) el.innerHTML = '';
        };

        loadRemote(
          url,
          dst,
          size_mb,
          cbProgress,
          storeFS,
          cbCancel,
          printTextarea
        );
      }

      //
      // microphone
      //

      const kSampleRate = 16000;
      const kRestartRecording_s = 120;
      const kIntervalAudio_ms = 5000; // pass the recorded audio to the C++ instance at this rate

      var mediaRecorder = null;
      var doRecording = false;
      var startTime = 0;

      window.AudioContext = window.AudioContext || window.webkitAudioContext;
      window.OfflineAudioContext =
        window.OfflineAudioContext || window.webkitOfflineAudioContext;

      function stopRecording() {
        Module.set_status('paused');
        doRecording = false;
        audio0 = null;
        audio = null;
        context = null;
      }

      function startRecording() {
        if (!context) {
        
          context = new AudioContext({
            sampleRate: kSampleRate,
            channelCount: 1,
            echoCancellation: false,
            autoGainControl: true,
            noiseSuppression: true,
          });

   

        }

        Module.set_status('');

        document.getElementById('start').disabled = true;
        document.getElementById('stop').disabled = false;

        doRecording = true;
        startTime = Date.now();

        var chunks = [];
        var stream = null;

        // Use startAudioCapture directly since we're in the renderer process
        window.startAudioCapture()
          .then(function (mediaStream) {
            stream = mediaStream;
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = function (e) {
              chunks.push(e.data);

              var blob = new Blob(chunks, { type: 'audio/ogg; codecs=opus' });
              var reader = new FileReader();

              reader.onload = function (event) {
                var buf = new Uint8Array(reader.result);

                if (!context) {
                  return;
                }
                context.decodeAudioData(
                  buf.buffer,
                  function (audioBuffer) {
                    var offlineContext = new OfflineAudioContext(
                      audioBuffer.numberOfChannels,
                      audioBuffer.length,
                      audioBuffer.sampleRate
                    );
                    var source = offlineContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(offlineContext.destination);
                    source.start(0);

                    offlineContext
                      .startRendering()
                      .then(function (renderedBuffer) {
                        audio = renderedBuffer.getChannelData(0);

                        var audioAll = new Float32Array(
                          audio0 == null
                            ? audio.length
                            : audio0.length + audio.length
                        );
                        if (audio0 != null) {
                          audioAll.set(audio0, 0);
                        }
                        audioAll.set(audio, audio0 == null ? 0 : audio0.length);

                        if (instance) {
                          Module.set_audio(instance, audioAll);
                        }
                      });
                  },
                  function (e) {
                    audio = null;
                  }
                );
              };

              reader.readAsArrayBuffer(blob);
            };

            mediaRecorder.onstop = function (e) {
              if (doRecording) {
                setTimeout(function () {
                  startRecording();
                });
              }
            };

            mediaRecorder.start(kIntervalAudio_ms);
          })
          .catch(function (err) {
            printTextarea('js: error getting audio stream: ' + err);
          });

        var interval = setInterval(function () {
          if (!doRecording) {
            clearInterval(interval);
            mediaRecorder.stop();
            stream.getTracks().forEach(function (track) {
              track.stop();
            });

            document.getElementById('start').disabled = false;
            document.getElementById('stop').disabled = true;

            mediaRecorder = null;
          }

          // if audio length is more than kRestartRecording_s seconds, restart recording
          if (
            audio != null &&
            audio.length > kSampleRate * kRestartRecording_s
          ) {
            if (doRecording) {
              clearInterval(interval);
              audio0 = audio;
              audio = null;
              mediaRecorder.stop();
              stream.getTracks().forEach(function (track) {
                track.stop();
              });
            }
          }
        }, 100);
      }

      //
      // main
      //

      var nLines = 0;
      var intervalUpdate = null;
      var transcribedAll = '';
      var accumulatedTranscription = ''; // Add accumulated transcription variable

      function onStart() {
        transcribedAll = '';
        accumulatedTranscription = ''; // Reset accumulated transcription
        
        if (!instance) {
          instance = Module.init('whisper.bin');

          if (instance) {
            printTextarea('js: whisper initialized, instance: ' + instance);
          }
        }

        if (!instance) {
          printTextarea('js: failed to initialize whisper');
          return;
        }

        startRecording();

        intervalUpdate = setInterval(async function () {
          var transcribed = Module.get_transcribed();

          if (transcribed != null && transcribed.length > 1) {
            transcribedAll += transcribed + '<br>';
            accumulatedTranscription += transcribed + ' '; // Accumulate all transcribed text
            nLines++;

            // if more than 10 lines, remove the first line
            if (nLines > 10) {
              var i = transcribedAll.indexOf('<br>');
              if (i > 0) {
                transcribedAll = transcribedAll.substring(i + 4);
                nLines--;
              }
            }
          }

          document.getElementById('state-status').innerHTML = Module.get_status();
          document.getElementById('state-transcribed').innerHTML = transcribedAll;
        }, 100);
      }

      async function onStop() {
        console.log('Stopping recording...');
        if (!instance) {
          return;
        }

        document.getElementById('start').disabled = false;
        document.getElementById('stop').disabled = true;

        stopRecording();
        clearInterval(intervalUpdate);

        // Reset status text
        document.getElementById('state-status').innerHTML = 'not started';

        // Only send the accumulated text to the LLM when stopping
        if (accumulatedTranscription && accumulatedTranscription.trim().length > 0) {
          try {
            console.log('Processing transcription:', accumulatedTranscription.trim());
            const llmOutput = document.getElementById('llm-output');
            llmOutput.textContent = '';
            
            const api = await waitForApi();
            console.log('Got API instance for transcription processing');
            
            await api.directOllamaQuery(
              accumulatedTranscription.trim(),
              (chunk) => {
                console.log('Renderer received transcription response chunk:', chunk);
                if (chunk && chunk.length > 0) {
                  // Append each chunk to the response div
                  llmOutput.textContent += chunk;
                  // Force scroll to bottom to show new content
                  llmOutput.scrollTop = llmOutput.scrollHeight;
                }
              },
              ollamaService.systemPrompt,
              ollamaService.model
            );
            console.log('Transcription processing complete');
          } catch (error) {
            console.error('Error getting LLM response:', error);
            const llmOutput = document.getElementById('llm-output');
            llmOutput.textContent = 'Error: ' + error.message;
          }
        }
      }
    </script>
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        //Automatically download smallest quantized model
        if (typeof loadWhisper === 'function') {
          loadWhisper('base-en-q5_1');
        } else {
          console.error('loadWhisper function not found');
        }
      });
    </script>
    <script type="module" src="./src/renderer.ts"></script>
    <script type="text/javascript" src="./src/stream.js"></script>
<script>
  console.log(window.myCustomData); // This will print "Hello from main process"
</script>
  </body>
</html>