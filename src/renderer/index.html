<!DOCTYPE html>
<html lang="en-us">
  
  <head>
    <meta http-equiv="Content-Security-Policy" content="script-src 'self' 'unsafe-eval' 'unsafe-inline'; object-src 'self'">
    <title>Real-time Local Speech To Text</title>

    <style>
      :root {
        --primary-color: #0078D4;
        --background-color: #f9f9f9;
        --card-background: #ffffff;
        --text-color: #323130;
        --border-radius: 4px;
        --spacing: 20px;
      }

      body {
        font-family: 'Segoe UI', -apple-system, BlinkMacSystemFont, sans-serif;
        font-size: 14px;
        margin: 0;
        padding: var(--spacing);
        background-color: var(--background-color);
        color: var(--text-color);
        line-height: 1.5;
      }

      #main-container {
        max-width: 1200px;
        margin: 0 auto;
        padding: var(--spacing);
      }

      .card {
        background: var(--card-background);
        border-radius: var(--border-radius);
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        padding: var(--spacing);
        margin-bottom: var(--spacing);
      }

      button {
        background-color: var(--primary-color);
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: var(--border-radius);
        cursor: pointer;
        font-size: 14px;
        font-weight: 500;
        transition: background-color 0.2s ease;
      }

      button:hover {
        background-color: #106EBE;
      }

      button:disabled {
        background-color: #C8C8C8;
        cursor: not-allowed;
      }

      button:not(:last-child) {
        margin-right: 10px;
      }

      #output {
        width: 100%;
        margin: var(--spacing) 0;
        padding: 15px;
        background-color: #2D2D2D;
        color: #E8E8E8;
        font-family: 'Cascadia Code', 'Consolas', monospace;
        font-size: 13px;
        border-radius: var(--border-radius);
        white-space: pre-wrap;
        overflow-x: auto;
      }

      #state {
        margin-top: var(--spacing);
      }

      #state-transcribed {
        background-color: var(--card-background);
        border: 1px solid #E1E1E1;
        border-radius: var(--border-radius);
        padding: 15px;
        margin: var(--spacing) 0;
        max-height: 300px;
        overflow-y: auto;
      }

      #system-prompt-container {
        margin: var(--spacing) 0;
      }

      #system-prompt {
        width: 100%;
        padding: 10px;
        border: 1px solid #E1E1E1;
        border-radius: var(--border-radius);
        font-family: inherit;
        font-size: 14px;
        resize: vertical;
        margin-bottom: 10px;
      }

      #llm-response {
        margin-top: var(--spacing);
      }

      #llm-output {
        max-height: 400px;
        overflow-y: auto;
        padding: 15px;
        background-color: var(--card-background);
        border: 1px solid #E1E1E1;
        border-radius: var(--border-radius);
        font-family: inherit;
        line-height: 1.6;
      }

      .response-item {
        margin-bottom: 15px;
        padding: 15px;
        border-bottom: 1px solid #E1E1E1;
        animation: fadeIn 0.3s ease-in;
      }

      .streaming-response {
        display: inline-block;
        min-height: 1em;
      }

      @keyframes fadeIn {
        from { opacity: 0; transform: translateY(5px); }
        to { opacity: 1; transform: translateY(0); }
      }

      .response-item:last-child {
        border-bottom: none;
      }

      h3 {
        color: var(--text-color);
        font-weight: 600;
        margin: 0 0 15px 0;
      }

      #model-whisper {
        margin-bottom: var(--spacing);
      }

      #state-status {
        color: var(--primary-color);
        font-weight: 500;
      }

      hr {
        border: none;
        border-top: 1px solid #E1E1E1;
        margin: var(--spacing) 0;
      }

      .status-container {
        margin-bottom: var(--spacing);
      }

      .transcription-container {
        margin-bottom: var(--spacing);
      }

      .model-info {
        display: flex;
        flex-direction: column;
        gap: 10px;
      }

      .model-info div {
        display: flex;
        align-items: center;
        gap: 8px;
      }

      .model-info strong {
        color: var(--text-color);
        min-width: 120px;
      }

      #ollama-model-status, #model-whisper-status {
        color: var(--primary-color);
        font-weight: 500;
      }

      #fetch-whisper-progress {
        color: #666;
        font-size: 0.9em;
        margin-left: 8px;
      }
    </style>

  </head>
  <body>
    <div id="main-container">
      <h1>Real-time Local Speech To Text</h1>

      <div id="model-whisper" class="card">
        <h3>Model Status</h3>
        <div class="model-info">
          <div>
            <strong>Whisper Model:</strong> <span id="model-whisper-status">tiny-en-q5_1</span>
            <span id="fetch-whisper-progress"></span>
          </div>
          <div>
            <strong>LLM Model:</strong> <span id="ollama-model-status">llama3.2</span>
          </div>
        </div>
      </div>

      <div id="input" class="card">
        <h3>Controls</h3>
        <button id="start" onclick="onStart()" disabled>Start Listening</button>
        <button id="stop" onclick="onStop()" disabled>Stop Listening</button>
      </div>

      <div id="state" class="card">
        <div class="status-container">
          <h3>Status</h3>
          <span id="state-status">not started</span>
        </div>

        <div id="system-prompt-container">
          <h3>System Prompt</h3>
          <textarea id="system-prompt" rows="4">You are a helpful AI assistant. Respond to the user's input in a clear and concise manner.</textarea>
          <button onclick="updateSystemPrompt()">Update System Prompt</button>
        </div>

        <div class="transcription-container">
          <h3>Transcription</h3>
          <pre id="state-transcribed">[The transcribed text will be displayed here]</pre>
        </div>

        <div id="llm-response">
          <h3>LLM Response</h3>
          <div id="llm-output">[LLM responses will appear here]</div>
        </div>
      </div>
    </div>

    <script type="text/javascript" src="./src/helpers.js"></script>
    <script type="text/javascript" src="./src/ollama.js"></script>
    <script type="text/javascript">
       // web audio context
       var context = null;

      // audio data
      var audio = null;
      var audio0 = null;

      // the stream instance
      var instance = null;

      // model names
      var model_whisper = 'tiny-en-q5_1';
      var model_llm = 'llama3.2';

      // ollama service instance
      var ollamaService = null;

      function updateModelStatus() {
        if (ollamaService) {
          const modelStatus = document.getElementById('ollama-model-status');
          modelStatus.textContent = ollamaService.model;
        }
      }

      // Initialize the model display
      document.addEventListener('DOMContentLoaded', function() {
        document.getElementById('model-whisper-status').textContent = model_whisper;
        document.getElementById('ollama-model-status').textContent = model_llm;
      });

      //
      // fetch models
      //

      let dbVersion = 1;
      let dbName = 'whisper-voice';
      let indexedDB =
        window.indexedDB ||
        window.mozIndexedDB ||
        window.webkitIndexedDB ||
        window.msIndexedDB;

      function storeFS(fname, buf) {
        // write to WASM file using FS_createDataFile
        // if the file exists, delete it
        try {
          Module.FS_unlink(fname);
        } catch (e) {
          // ignore
        }

        Module.FS_createDataFile('/', fname, buf, true, true);

        printTextarea(
          'storeFS: stored model: ' + fname + ' size: ' + buf.length
        );


          document.getElementById('start').disabled = false;
          document.getElementById('stop').disabled = true;
        
      }

      function loadWhisper(model) {
        let urls = {
          'tiny.en': './src/ggml-model-whisper-tiny.en.bin',
          'tiny-en-q5_1': './src/ggml-model-whisper-tiny.en-q5_1.bin',
          'base-en-q5_1': './src/ggml-model-whisper-base.en-q5_1.bin',
        };

        let sizes = {
          'tiny.en': 59,
          'tiny-en-q5_1': 32,
          'base-en-q5_1': 77,
        };

        let url = urls[model];
        let dst = 'whisper.bin';
        let size_mb = sizes[model];

        model_whisper = model;

        cbProgress = function (p) {
          let el = document.getElementById('fetch-whisper-progress');
          el.innerHTML = Math.round(100 * p) + '%';
        };

        cbCancel = function () {
          var el;
          el = document.getElementById('fetch-whisper-tiny-en');
          if (el) el.style.display = 'inline-block';

          el = document.getElementById('fetch-whisper-tiny-en-q5_1');
          if (el) el.style.display = 'inline-block';
          el = document.getElementById('fetch-whisper-base-en-q5_1');
          if (el) el.style.display = 'inline-block';

          el = document.getElementById('model-whisper-status');
          if (el) el.innerHTML = '';
        };

        loadRemote(
          url,
          dst,
          size_mb,
          cbProgress,
          storeFS,
          cbCancel,
          printTextarea
        );
      }

      //
      // microphone
      //

      const kSampleRate = 16000;
      const kRestartRecording_s = 120;
      const kIntervalAudio_ms = 5000; // pass the recorded audio to the C++ instance at this rate

      var mediaRecorder = null;
      var doRecording = false;
      var startTime = 0;

      window.AudioContext = window.AudioContext || window.webkitAudioContext;
      window.OfflineAudioContext =
        window.OfflineAudioContext || window.webkitOfflineAudioContext;

      function stopRecording() {
        Module.set_status('paused');
        doRecording = false;
        audio0 = null;
        audio = null;
        context = null;
      }

      function startRecording() {
        if (!context) {
        
          context = new AudioContext({
            sampleRate: kSampleRate,
            channelCount: 1,
            echoCancellation: false,
            autoGainControl: true,
            noiseSuppression: true,
          });

   

        }

        Module.set_status('');

        document.getElementById('start').disabled = true;
        document.getElementById('stop').disabled = false;

        doRecording = true;
        startTime = Date.now();

        var chunks = [];
        var stream = null;

        // Use startAudioCapture directly since we're in the renderer process
        window.startAudioCapture()
          .then(function (mediaStream) {
            stream = mediaStream;
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = function (e) {
              chunks.push(e.data);

              var blob = new Blob(chunks, { type: 'audio/ogg; codecs=opus' });
              var reader = new FileReader();

              reader.onload = function (event) {
                var buf = new Uint8Array(reader.result);

                if (!context) {
                  return;
                }
                context.decodeAudioData(
                  buf.buffer,
                  function (audioBuffer) {
                    var offlineContext = new OfflineAudioContext(
                      audioBuffer.numberOfChannels,
                      audioBuffer.length,
                      audioBuffer.sampleRate
                    );
                    var source = offlineContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(offlineContext.destination);
                    source.start(0);

                    offlineContext
                      .startRendering()
                      .then(function (renderedBuffer) {
                        audio = renderedBuffer.getChannelData(0);

                        var audioAll = new Float32Array(
                          audio0 == null
                            ? audio.length
                            : audio0.length + audio.length
                        );
                        if (audio0 != null) {
                          audioAll.set(audio0, 0);
                        }
                        audioAll.set(audio, audio0 == null ? 0 : audio0.length);

                        if (instance) {
                          Module.set_audio(instance, audioAll);
                        }
                      });
                  },
                  function (e) {
                    audio = null;
                  }
                );
              };

              reader.readAsArrayBuffer(blob);
            };

            mediaRecorder.onstop = function (e) {
              if (doRecording) {
                setTimeout(function () {
                  startRecording();
                });
              }
            };

            mediaRecorder.start(kIntervalAudio_ms);
          })
          .catch(function (err) {
            printTextarea('js: error getting audio stream: ' + err);
          });

        var interval = setInterval(function () {
          if (!doRecording) {
            clearInterval(interval);
            mediaRecorder.stop();
            stream.getTracks().forEach(function (track) {
              track.stop();
            });

            document.getElementById('start').disabled = false;
            document.getElementById('stop').disabled = true;

            mediaRecorder = null;
          }

          // if audio length is more than kRestartRecording_s seconds, restart recording
          if (
            audio != null &&
            audio.length > kSampleRate * kRestartRecording_s
          ) {
            if (doRecording) {
              clearInterval(interval);
              audio0 = audio;
              audio = null;
              mediaRecorder.stop();
              stream.getTracks().forEach(function (track) {
                track.stop();
              });
            }
          }
        }, 100);
      }

      //
      // main
      //

      var nLines = 0;
      var intervalUpdate = null;
      var transcribedAll = '';
      var accumulatedTranscription = ''; // Add accumulated transcription variable

      function onStart() {
        transcribedAll = '';
        accumulatedTranscription = ''; // Reset accumulated transcription
        
        if (!instance) {
          instance = Module.init('whisper.bin');

          if (instance) {
            printTextarea('js: whisper initialized, instance: ' + instance);
          }
        }

        if (!instance) {
          printTextarea('js: failed to initialize whisper');
          return;
        }

        if (!ollamaService) {
          try {
            ollamaService = new OllamaService();
            console.log('Ollama service initialized');
            updateModelStatus(); // Update the model status display
          } catch (error) {
            console.error('Failed to initialize Ollama service:', error);
            printTextarea('Failed to initialize Ollama service: ' + error.message);
          }
        }

        startRecording();

        intervalUpdate = setInterval(async function () {
          var transcribed = Module.get_transcribed();

          if (transcribed != null && transcribed.length > 1) {
            transcribedAll += transcribed + '<br>';
            accumulatedTranscription += transcribed + ' '; // Accumulate all transcribed text
            nLines++;

            // if more than 10 lines, remove the first line
            if (nLines > 10) {
              var i = transcribedAll.indexOf('<br>');
              if (i > 0) {
                transcribedAll = transcribedAll.substring(i + 4);
                nLines--;
              }
            }
          }

          document.getElementById('state-status').innerHTML = Module.get_status();
          document.getElementById('state-transcribed').innerHTML = transcribedAll;
        }, 100);
      }

      function onStop() {
        stopRecording();
        clearInterval(intervalUpdate);

        // Reset status text
        document.getElementById('state-status').innerHTML = 'not started';

        // Only send the accumulated text to the LLM when stopping
        if (accumulatedTranscription && accumulatedTranscription.trim().length > 0) {
          try {
            const llmOutput = document.getElementById('llm-output');
            ollamaService.generateResponse(accumulatedTranscription.trim(), llmOutput);
          } catch (error) {
            console.error('Error getting LLM response:', error);
          }
        }
      }

      //
      //Automatically download smallest quantized model
      loadWhisper('base-en-q5_1')



    </script>
  
    <script type="module" src="./src/renderer.ts"></script>
    <script type="text/javascript" src="./src/stream.js"
  ></script>
<script>
  console.log(window.myCustomData); // This will print "Hello from main process"
</script>
  </body>
</html>